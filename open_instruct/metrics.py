import torch
from typing import List, Dict, Any
from evaluate import load
import numpy as np
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForSequenceClassification


class IntentAccuracy:
    def __init__(self) -> None:
        # Initialize the tokenizer and model
        self._tokenizer = AutoTokenizer.from_pretrained(
            "rajkumarrrk/roberta-daily-dialog-intent-classifier"
        )
        self._model = AutoModelForSequenceClassification.from_pretrained(
            "rajkumarrrk/roberta-daily-dialog-intent-classifier"
        )

        # Set device to GPU if available, else CPU
        if torch.cuda.is_available():
            self._device = f"cuda:{torch.cuda.device_count() - 1}"
        else:
            self._device = "cpu"
        self._model = self._model.to(self._device)
    
    def get_model(self):
        return self._model

    def compute(
        self,
        prompt_texts: List[str],
        generated_texts: List[str],
        reference_texts: List[List[str]] = None,  # Not required for intent classification
        meta_infos: List[Dict[str, Any]] = None,
        model=None,
        split_name: str = None,
    ) -> torch.Tensor:
        """
        Compute intent probabilities for a batch of generated texts and return them as a tensor.

        Args:
            prompt_texts (List[str]): List of prompts (dialog histories).
            generated_texts (List[str]): List of generated texts (responses).
            reference_texts (List[List[str]], optional): Not used here.
            meta_infos (List[Dict[str, Any]]): List of metadata dictionaries, each containing the target intent.

        Returns:
            torch.Tensor: A tensor of size (batch_size,) containing probabilities for the target intent class.
        """
        def get_input_for_classifier(prompt, generated_text):
            # Combine the last utterance of the prompt with the generated response
            history = prompt.split("[EOU]")
            history = [utt.strip() for utt in history if utt.strip()]
            last_utterance = history[-1]
            input_text = last_utterance + " " + generated_text
            return input_text

        # Create input texts for the classifier
        input_texts = [
            get_input_for_classifier(prompt, gen)
            for prompt, gen in zip(prompt_texts, generated_texts)
        ]

        # Extract target intents from meta_infos
        target_intents = torch.tensor(
            [info["intent"][0] - 1 for info in meta_infos], device=self._device
        )

        # Tokenize input texts
        encoded = self._tokenizer(
            input_texts, return_tensors="pt", truncation=True, padding=True
        )

        # Perform inference with the intent classifier
        with torch.no_grad():
            outputs = self._model(
                input_ids=encoded.input_ids.to(self._device),
                attention_mask=encoded.attention_mask.to(self._device),
            )
            # Extract logits and apply softmax to get probabilities
            probabilities = torch.softmax(outputs.logits, dim=1)

        # Get the probability for the target class
        target_probabilities = probabilities[
            torch.arange(len(target_intents)), target_intents
        ]

        # Return the probabilities as a tensor of shape (batch_size,)
        return target_probabilities

class MeteorMetric:
    def __init__(self) -> None:
        # Initialize the METEOR metric from the evaluate library
        self._metric = load("meteor")

    def compute(
        self,
        prompt_texts: List[str],
        generated_texts: List[str],
        reference_texts: List[List[str]],
        meta_infos: List[Dict[str, Any]] = None,
    ) -> torch.Tensor:
        """
        Compute METEOR scores for a batch of generated texts and return them as a PyTorch tensor.

        Args:
            prompt_texts (List[str]): List of prompt texts (not used for METEOR but included for API consistency).
            generated_texts (List[str]): List of texts generated by the model.
            reference_texts (List[List[str]]): List of reference texts for comparison, where each generated text has its own list of references.
            meta_infos (List[Dict[str, Any]], optional): Additional metadata (not used here).

        Returns:
            torch.Tensor: A tensor of size (batch_size,) containing the METEOR scores for each generated text.
        """
        # Compute individual METEOR scores for each generated text and its corresponding reference(s)
        batch_scores = []
        for prediction, reference in zip(generated_texts, reference_texts):
            # Compute METEOR score for a single prediction-reference pair
            score = self._metric.compute(predictions=[prediction], references=reference)["meteor"]
            batch_scores.append(score)

        # Convert the list of scores into a PyTorch tensor
        return torch.tensor(batch_scores, dtype=torch.float32)
    


if __name__ == "__main__":
    # # Initialize the metric
    # meteor_metric = MeteorMetric()

    # # Example generated texts
    # generated_texts = [
    #     "The cat is sitting on the mat.",
    #     "The dog is lying under the table.",
    # ]

    # # Single reference text (replicated for all generated texts)
    # single_reference = "The cat sits on the mat."
    # reference_texts = [[single_reference] for _ in generated_texts]

    # # Compute METEOR scores as a tensor
    # meteor_scores = meteor_metric.compute(
    #     prompt_texts=None,  # Prompts are not required for METEOR
    #     generated_texts=generated_texts,
    #     reference_texts=reference_texts,
    # )

    # # Print the results
    # print("METEOR Scores as Tensor:", meteor_scores)
    # print("Tensor Shape:", meteor_scores.shape)


    # # Initialize the Intent metric
    # intent_metric = IntentAccuracyDailyDialog()

    # # Example data
    # prompt_texts = [
    #     "Hello! How are you today? [EOU] I'm doing great, thank you. [EOU]",
    #     "What do you want to do? [EOU] Let's go to the park. [EOU]"
    # ]
    # generated_texts = [
    #     "I'm doing well, thanks!",
    #     "Sure, let's go there."
    # ]
    # meta_infos = [
    #     {"intent": [2]},  # Target intent index for the first example
    #     {"intent": [3]}   # Target intent index for the second example
    # ]

    # # Compute intent matching scores
    # intent_scores = intent_metric.compute(
    #     prompt_texts=prompt_texts,
    #     generated_texts=generated_texts,
    #     meta_infos=meta_infos
    # )

    # # Print the results
    # print("Intent Matching Scores (Tensor):", intent_scores)
    # print("Tensor Shape:", intent_scores.shape)

    dataset = load_dataset("daily_dialog")

    print("Available Splits:", dataset.keys())

    # Check the column names in a split
    print("Column Names:", dataset["train"].column_names)

    # Access a sample row
    print("Sample Row:", dataset["train"][0])

    # Iterate through columns in a row
    print("\nColumns and Values:")
    for column, value in dataset["train"][0].items():
        print(f"{column}: {value}")