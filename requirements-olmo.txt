# TODO When updating flash-attn or torch in the future, make sure to update the version in the Dockerfile 
torch<=2.3.0
scipy
packaging
sentencepiece
datasets
accelerate>=0.21.0
peft>=0.4.0
bitsandbytes>=0.41.1
evaluate>=0.4.0
tokenizers>=0.13.3
protobuf
transformers>=4.40
openai>=1.0.0
tiktoken
rouge_score
tensorboard
wandb
gradio>=3.50.2
termcolor
jsonlines
unidic-lite
einops
flash-attn==2.5.8 # should really only be in dockerfile. Local env often doesn't have GPUs
fire
alpaca-eval==0.6.2
# for human eval web app
flask
vllm>=0.4.2 # for compatibility with OLMo models in transition to Transformers integration
openpyxl
# for ifeval
nltk
langdetect
immutabledict